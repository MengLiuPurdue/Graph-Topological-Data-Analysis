{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze chest X-ray dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "savepath = \"dataset/precomputed/chest_xray\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load precomputed graph and lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.load(f\"{savepath}/labels.npy\")\n",
    "with open(f\"{savepath}/train_nodes.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    train_nodes = [int(i.strip()) for i in lines]\n",
    "with open(f\"{savepath}/test_nodes.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_nodes = [int(i.strip()) for i in lines]\n",
    "with open(f\"{savepath}/test_img_names.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    test_img_names = [i.strip() for i in lines]\n",
    "ei,ej,e = [],[],[]\n",
    "with open(f\"{savepath}/edge_list.txt\",\"r\") as f:\n",
    "    lines = f.readlines()\n",
    "    num_nodes = int(lines[0].strip().split(' ')[0])\n",
    "    for line in lines[1::]:\n",
    "        line = line.strip().split(' ')\n",
    "        ei.append(int(line[0]))\n",
    "        ej.append(int(line[1]))\n",
    "        e.append(int(line[2]))\n",
    "G = sp.csr_matrix((e,(ei,ej)),(num_nodes,num_nodes))\n",
    "preds = np.load(f\"{savepath}/prediction_lens.npy\")\n",
    "extra_lens = np.load(f\"{savepath}/extra_lens.npy\")\n",
    "pred_labels = np.argmax(preds,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Reeb graph and estimated errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocess lens..\n",
      "Merge reeb nodes...\n",
      "Build reeb graph...\n",
      "Total time for building reeb graph is 29.21596622467041 seconds\n",
      "Compute mixing rate for each sample\n"
     ]
    }
   ],
   "source": [
    "from GTDA.GTDA_utils import compute_reeb, NN_model\n",
    "from GTDA.GTDA import GTDA\n",
    "\n",
    "nn_model = NN_model()\n",
    "nn_model.preds = preds\n",
    "nn_model.labels = labels\n",
    "nn_model.A = G\n",
    "nn_model.train_mask = np.zeros(G.shape[0])\n",
    "nn_model.train_mask[train_nodes] = 1\n",
    "nn_model.val_mask = np.zeros(G.shape[0])\n",
    "nn_model.test_mask = np.zeros(G.shape[0])\n",
    "nn_model.test_mask[test_nodes] = 1\n",
    "smallest_component = 50\n",
    "overlap = 0.005\n",
    "labels_to_eval = list(range(preds.shape[1]))\n",
    "GTDA_record = compute_reeb(GTDA,nn_model,labels_to_eval,smallest_component,overlap,extra_lens=extra_lens,\n",
    "    node_size_thd=5,reeb_component_thd=5,nprocs=10,device='cuda',nsteps_preprocess=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare with expert labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type\tExpert_Labels_in_Component\tIncorrect_by_Experts\tFlagged_as_Problematic\tPrecision\tRecall\n",
      "Single_Component\t53\t18\t17\t0.82\t0.78\n",
      "Single_Component\t10\t5\t5\t1.0\t1.0\n",
      "Single_Component\t9\t5\t4\t0.25\t0.2\n",
      "Single_Component\t19\t4\t7\t0.57\t1.0\n",
      "Single_Component\t9\t4\t5\t0.8\t1.0\n",
      "Single_Component\t10\t4\t3\t0.33\t0.25\n",
      "Single_Component\t7\t4\t2\t1.0\t0.5\n",
      "Single_Component\t8\t4\t5\t0.6\t0.75\n",
      "Single_Component\t14\t4\t4\t1.0\t1.0\n",
      "Single_Component\t4\t4\t2\t1.0\t0.5\n",
      "Single_Component\t7\t4\t3\t0.33\t0.25\n",
      "Single_Component\t10\t3\t2\t0.0\t0.0\n",
      "Single_Component\t6\t3\t1\t0.0\t0.0\n",
      "Single_Component\t4\t3\t2\t0.5\t0.33\n",
      "Single_Component\t6\t3\t3\t0.33\t0.33\n",
      "Single_Component\t3\t3\t2\t1.0\t0.67\n",
      "Single_Component\t5\t3\t3\t1.0\t1.0\n",
      "Single_Component\t5\t3\t2\t0.5\t0.33\n",
      "Single_Component\t8\t3\t5\t0.4\t0.67\n",
      "Single_Component\t7\t3\t4\t0.5\t0.67\n",
      "Single_Component\t19\t3\t8\t0.25\t0.67\n",
      "Single_Component\t9\t3\t8\t0.38\t1.0\n",
      "Single_Component\t8\t3\t3\t0.33\t0.33\n",
      "Single_Component\t8\t3\t4\t0.5\t0.67\n",
      "Components_with_2_incorrect_labels\t135\t56\t50\t0.74\t0.66\n",
      "Components_with_1_incorrect_label\t219\t67\t78\t0.5\t0.58\n",
      "Components_with_0_incorrect_label\t208\t0\t33\t0.0\tNaN\n"
     ]
    }
   ],
   "source": [
    "from GTDA.GTDA_utils import find_components\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "n = nn_model.preds.shape[0]\n",
    "pred_labels = np.argmax(nn_model.preds,1)\n",
    "gtda = GTDA_record['gtda']\n",
    "g_reeb = GTDA_record['g_reeb']\n",
    "reeb_components = find_components(g_reeb,size_thd=0)[1]\n",
    "reeb_components_to_nodes = {}\n",
    "for i,reeb_component in enumerate(reeb_components):\n",
    "    nodes = []\n",
    "    for reeb_node in reeb_component:\n",
    "        nodes += gtda.final_components_filtered[gtda.filtered_nodes[reeb_node]]\n",
    "    if len(nodes) > 0:\n",
    "        reeb_components_to_nodes[i] = np.unique(nodes)\n",
    "\n",
    "node_to_component_id = np.array([-1]*n)\n",
    "for i,component in reeb_components_to_nodes.items():\n",
    "    for node in component:\n",
    "        node_to_component_id[node] = i\n",
    "\n",
    "# 'test_labels.csv' can be obtained from 'https://cloud.google.com/healthcare-api/docs/resources/public-datasets/nih-chest'.\n",
    "pathDirData = 'dataset/chest_xray'\n",
    "expert_labels = pd.read_table(f'{pathDirData}/all_findings_expert_labels/test_labels.csv',delimiter=',')\n",
    "expert_tested_imgs = expert_labels['Image ID'].values\n",
    "expert_labels = expert_labels['Abnormal'].values\n",
    "expert_labels[np.nonzero(expert_labels=='NO')] = 0\n",
    "expert_labels[np.nonzero(expert_labels=='YES')] = 1\n",
    "expert_labels = expert_labels.astype(np.int64)\n",
    "test_img_ids = {}\n",
    "for i,img in enumerate(test_img_names):\n",
    "    test_img_ids[img] = test_nodes[i]\n",
    "\n",
    "expert_tested_imgs = np.array([test_img_ids[i] for i in expert_tested_imgs])\n",
    "expert_tested_incorrect_imgs = expert_tested_imgs[np.nonzero(nn_model.labels[expert_tested_imgs] != expert_labels)[0]]\n",
    "print(\"Type\\tExpert_Labels_in_Component\\tIncorrect_by_Experts\\tFlagged_as_Problematic\\tPrecision\\tRecall\")\n",
    "#%%\n",
    "thd = 0.5\n",
    "all_estimate = []\n",
    "all_labels = []\n",
    "cnt = Counter([node_to_component_id[k] for k in expert_tested_incorrect_imgs])\n",
    "cnt_experts = Counter([node_to_component_id[k] for k in expert_tested_imgs])\n",
    "# Single component\n",
    "component_indices = []\n",
    "all_tp = 0\n",
    "all_num_total = 0\n",
    "all_num_pos = 0\n",
    "all_num_experts = 0\n",
    "for i,k in cnt.items(): \n",
    "    if k >= 3:\n",
    "        component_indices.append(i)\n",
    "for component_index,num_pos in cnt.most_common(len(component_indices)):\n",
    "    tp = 0\n",
    "    num_total = 0\n",
    "    num_experts = 0\n",
    "    for i in reeb_components_to_nodes[component_index]:\n",
    "        if i in set(expert_tested_imgs):\n",
    "            num_experts += 1\n",
    "            error = int(nn_model.labels[i]!=pred_labels[i])\n",
    "            num_total += (np.abs(error-gtda.sample_colors_mixing[i])>thd)\n",
    "            tp += ((i in set(expert_tested_incorrect_imgs)) * (np.abs(error-gtda.sample_colors_mixing[i])>thd))\n",
    "            all_estimate.append(np.abs(error-gtda.sample_colors_mixing[i]))\n",
    "            all_labels.append(int(i in set(expert_tested_incorrect_imgs)))\n",
    "    all_tp += tp\n",
    "    all_num_total += num_total\n",
    "    all_num_pos += num_pos\n",
    "    all_num_experts += num_experts\n",
    "    print(f\"Single_Component\\t{num_experts}\\t{num_pos}\\t{num_total}\\t{round(tp/num_total,2)}\\t{round(tp/num_pos,2)}\")\n",
    "# Components with 2 incorrect expert labels\n",
    "component_indices = []\n",
    "for i,k in cnt.items(): \n",
    "    if k == 2:\n",
    "        component_indices.append(i)\n",
    "tp = 0\n",
    "num_total = 0\n",
    "num_pos = 0\n",
    "num_experts = 0\n",
    "for component_index in component_indices:\n",
    "    num_pos += cnt[component_index]\n",
    "    for i in reeb_components_to_nodes[component_index]:\n",
    "        if i in set(expert_tested_imgs):\n",
    "            num_experts += 1\n",
    "            error = int(nn_model.labels[i]!=pred_labels[i])\n",
    "            num_total += (np.abs(error-gtda.sample_colors_mixing[i])>thd)\n",
    "            tp += ((i in set(expert_tested_incorrect_imgs)) * (np.abs(error-gtda.sample_colors_mixing[i])>thd))\n",
    "            all_estimate.append(np.abs(error-gtda.sample_colors_mixing[i]))\n",
    "            all_labels.append(int(i in set(expert_tested_incorrect_imgs)))\n",
    "all_tp += tp\n",
    "all_num_total += num_total\n",
    "all_num_pos += num_pos\n",
    "all_num_experts += num_experts\n",
    "print(f\"Components_with_2_incorrect_labels\\t{num_experts}\\t{num_pos}\\t{num_total}\\t{round(tp/num_total,2)}\\t{round(tp/num_pos,2)}\")\n",
    "# Components with 1 incorrect expert label\n",
    "component_indices = []\n",
    "for i,k in cnt.items(): \n",
    "    if k == 1:\n",
    "        component_indices.append(i)\n",
    "tp = 0\n",
    "num_total = 0\n",
    "num_pos = 0\n",
    "num_experts = 0\n",
    "for component_index in component_indices:\n",
    "    num_pos += cnt[component_index]\n",
    "    for i in reeb_components_to_nodes[component_index]:\n",
    "        if i in set(expert_tested_imgs):\n",
    "            num_experts += 1\n",
    "            error = int(nn_model.labels[i]!=pred_labels[i])\n",
    "            num_total += (np.abs(error-gtda.sample_colors_mixing[i])>thd)\n",
    "            tp += ((i in set(expert_tested_incorrect_imgs)) * (np.abs(error-gtda.sample_colors_mixing[i])>thd))\n",
    "            all_estimate.append(np.abs(error-gtda.sample_colors_mixing[i]))\n",
    "            all_labels.append(int(i in set(expert_tested_incorrect_imgs)))\n",
    "all_tp += tp\n",
    "all_num_total += num_total\n",
    "all_num_pos += num_pos\n",
    "all_num_experts += num_experts\n",
    "print(f\"Components_with_1_incorrect_label\\t{num_experts}\\t{num_pos}\\t{num_total}\\t{round(tp/num_total,2)}\\t{round(tp/num_pos,2)}\")\n",
    "# Components with 0 incorrect expert label\n",
    "component_indices = []\n",
    "for i,k in cnt_experts.items(): \n",
    "    if i not in cnt:\n",
    "        component_indices.append(i)\n",
    "tp = 0\n",
    "num_total = 0\n",
    "num_pos = 0\n",
    "num_experts = 0\n",
    "for component_index in component_indices:\n",
    "    num_pos += cnt[component_index]\n",
    "    for i in reeb_components_to_nodes[component_index]:\n",
    "        if i in set(expert_tested_imgs):\n",
    "            num_experts += 1\n",
    "            error = int(nn_model.labels[i]!=pred_labels[i])\n",
    "            num_total += (np.abs(error-gtda.sample_colors_mixing[i])>thd)\n",
    "            tp += ((i in set(expert_tested_incorrect_imgs)) * (np.abs(error-gtda.sample_colors_mixing[i])>thd))\n",
    "            all_estimate.append(np.abs(error-gtda.sample_colors_mixing[i]))\n",
    "            all_labels.append(int(i in set(expert_tested_incorrect_imgs)))\n",
    "all_tp += tp\n",
    "all_num_total += num_total\n",
    "all_num_pos += num_pos\n",
    "all_num_experts += num_experts\n",
    "print(f\"Components_with_0_incorrect_label\\t{num_experts}\\t{num_pos}\\t{num_total}\\t{round(tp/num_total,2)}\\tNaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC score is: 0.752949377949378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "print(\"AUC score is:\",roc_auc_score(all_labels,all_estimate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.9 ('GNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6948c9add599dc84fb5cea4167cec9ae9549be5f9ceab16e737a3bec58215a86"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
